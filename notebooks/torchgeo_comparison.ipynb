{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4af6a28",
      "metadata": {},
      "source": [
        "# Enhanced AI Model Comparison for Remote Sensing with TorchGeo\n",
        "\n",
        "This enhanced Jupyter Notebook allows you to:\n",
        "- Upload your own satellite imagery or use sample datasets\n",
        "- Compare two different pre-trained models side-by-side\n",
        "- Visualize results with detailed performance metrics\n",
        "- Export comparison results\n",
        "\n",
        "Built with [TorchGeo](https://github.com/microsoft/torchgeo) for seamless geospatial deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "installation",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary libraries (uncomment and run if not already installed)\n",
        "# !pip install torch torchvision torchgeo matplotlib seaborn pandas scikit-learn ipywidgets\n",
        "# !pip install rasterio pillow numpy pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14527af3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TorchGeo imports\n",
        "from torchgeo.datasets import EuroSAT, RESISC45\n",
        "from torchgeo.trainers import ClassificationTask\n",
        "from pytorch_lightning import Trainer\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# For file upload functionality\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config",
      "metadata": {},
      "source": [
        "## Step 2: Configuration and Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Available pre-trained models for comparison\n",
        "AVAILABLE_MODELS = {\n",
        "    'ResNet-18': 'resnet18',\n",
        "    'ResNet-34': 'resnet34',\n",
        "    'ResNet-50': 'resnet50',\n",
        "    'EfficientNet-B0': 'efficientnet_b0',\n",
        "    'EfficientNet-B1': 'efficientnet_b1',\n",
        "    'MobileNet-V2': 'mobilenet_v2',\n",
        "    'DenseNet-121': 'densenet121',\n",
        "    'VGG-16': 'vgg16'\n",
        "}\n",
        "\n",
        "# Dataset options\n",
        "AVAILABLE_DATASETS = {\n",
        "    'EuroSAT': 'eurosat',\n",
        "    'RESISC45': 'resisc45',\n",
        "    'Custom Upload': 'custom'\n",
        "}\n",
        "\n",
        "# Configuration class\n",
        "class ModelComparisonConfig:\n",
        "    def __init__(self):\n",
        "        self.model_1 = 'resnet18'\n",
        "        self.model_2 = 'resnet34'\n",
        "        self.dataset = 'eurosat'\n",
        "        self.batch_size = 32\n",
        "        self.num_epochs = 5\n",
        "        self.learning_rate = 1e-3\n",
        "        self.test_split = 0.2\n",
        "        \n",
        "config = ModelComparisonConfig()\n",
        "print(\"Configuration initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ui_section",
      "metadata": {},
      "source": [
        "## Step 3: Interactive Model and Dataset Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ui_widgets",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create interactive widgets for model selection\n",
        "model1_dropdown = widgets.Dropdown(\n",
        "    options=list(AVAILABLE_MODELS.keys()),\n",
        "    value='ResNet-18',\n",
        "    description='Model 1:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "model2_dropdown = widgets.Dropdown(\n",
        "    options=list(AVAILABLE_MODELS.keys()),\n",
        "    value='ResNet-34',\n",
        "    description='Model 2:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "dataset_dropdown = widgets.Dropdown(\n",
        "    options=list(AVAILABLE_DATASETS.keys()),\n",
        "    value='EuroSAT',\n",
        "    description='Dataset:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "epochs_slider = widgets.IntSlider(\n",
        "    value=5,\n",
        "    min=1,\n",
        "    max=20,\n",
        "    step=1,\n",
        "    description='Epochs:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "batch_size_dropdown = widgets.Dropdown(\n",
        "    options=[16, 32, 64, 128],\n",
        "    value=32,\n",
        "    description='Batch Size:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# File upload widget for custom datasets\n",
        "file_upload = widgets.FileUpload(\n",
        "    accept='.zip,.tar,.tar.gz',\n",
        "    multiple=False,\n",
        "    description='Upload Dataset',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Update configuration function\n",
        "def update_config(*args):\n",
        "    config.model_1 = AVAILABLE_MODELS[model1_dropdown.value]\n",
        "    config.model_2 = AVAILABLE_MODELS[model2_dropdown.value]\n",
        "    config.dataset = AVAILABLE_DATASETS[dataset_dropdown.value]\n",
        "    config.num_epochs = epochs_slider.value\n",
        "    config.batch_size = batch_size_dropdown.value\n",
        "\n",
        "# Attach observers\n",
        "model1_dropdown.observe(update_config, names='value')\n",
        "model2_dropdown.observe(update_config, names='value')\n",
        "dataset_dropdown.observe(update_config, names='value')\n",
        "epochs_slider.observe(update_config, names='value')\n",
        "batch_size_dropdown.observe(update_config, names='value')\n",
        "\n",
        "# Display widgets\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Model Comparison Configuration</h3>\"),\n",
        "    widgets.HBox([model1_dropdown, model2_dropdown]),\n",
        "    dataset_dropdown,\n",
        "    widgets.HBox([epochs_slider, batch_size_dropdown]),\n",
        "    file_upload\n",
        "]))\n",
        "\n",
        "update_config()  # Initialize config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data_loading",
      "metadata": {},
      "source": [
        "## Step 4: Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "data_loader",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(dataset_type, custom_path=None):\n",
        "    \"\"\"Load and prepare dataset based on selection\"\"\"\n",
        "    transforms = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    if dataset_type == 'eurosat':\n",
        "        dataset = EuroSAT(root=\"data/eurosat\", download=True, transforms=transforms)\n",
        "        class_names = [\n",
        "            'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
        "            'Industrial', 'Pasture', 'PermanentCrop', 'Residential',\n",
        "            'River', 'SeaLake'\n",
        "        ]\n",
        "    elif dataset_type == 'resisc45':\n",
        "        dataset = RESISC45(root=\"data/resisc45\", download=True, transforms=transforms)\n",
        "        class_names = [f\"Class_{i}\" for i in range(45)]  # Simplified for demo\n",
        "    elif dataset_type == 'custom' and custom_path:\n",
        "        # Handle custom dataset loading\n",
        "        # This would need to be implemented based on your custom data format\n",
        "        print(\"Custom dataset loading not fully implemented in this demo\")\n",
        "        return None, None, None\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown dataset type: {dataset_type}\")\n",
        "    \n",
        "    # Split dataset\n",
        "    total_size = len(dataset)\n",
        "    test_size = int(config.test_split * total_size)\n",
        "    train_size = total_size - test_size\n",
        "    \n",
        "    train_dataset, test_dataset = random_split(\n",
        "        dataset, [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    \n",
        "    return train_dataset, test_dataset, class_names\n",
        "\n",
        "def create_data_loaders(train_dataset, test_dataset, batch_size):\n",
        "    \"\"\"Create data loaders for training and testing\"\"\"\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        num_workers=2\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=False, \n",
        "        num_workers=2\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "print(\"Data loading functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_setup",
      "metadata": {},
      "source": [
        "## Step 5: Model Setup and Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(model_name, num_classes):\n",
        "    \"\"\"Create and configure a model\"\"\"\n",
        "    if model_name.startswith('resnet'):\n",
        "        model = getattr(models, model_name)(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif model_name.startswith('efficientnet'):\n",
        "        model = getattr(models, model_name)(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif model_name == 'mobilenet_v2':\n",
        "        model = models.mobilenet_v2(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif model_name.startswith('densenet'):\n",
        "        model = getattr(models, model_name)(pretrained=True)\n",
        "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Model {model_name} not supported\")\n",
        "    \n",
        "    return model.to(device)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, num_epochs, learning_rate, model_name):\n",
        "    \"\"\"Train a model and return training history\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': [],\n",
        "        'epoch_times': []\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        \n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            images = batch['image'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                images = batch['image'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "                \n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Calculate metrics\n",
        "        epoch_time = time.time() - start_time\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        \n",
        "        # Store history\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['epoch_times'].append(epoch_time)\n",
        "        \n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%, \"\n",
        "              f\"Time: {epoch_time:.2f}s\")\n",
        "    \n",
        "    return model, history\n",
        "\n",
        "def evaluate_model(model, test_loader, class_names):\n",
        "    \"\"\"Evaluate model and return detailed metrics\"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            images = batch['image'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted'\n",
        "    )\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': all_predictions,\n",
        "        'labels': all_labels\n",
        "    }\n",
        "\n",
        "print(\"Model training and evaluation functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "visualization",
      "metadata": {},
      "source": [
        "## Step 6: Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "viz_functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history1, history2, model1_name, model2_name):\n",
        "    \"\"\"Plot training history comparison\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    epochs = range(1, len(history1['train_loss']) + 1)\n",
        "    \n",
        "    # Training Loss\n",
        "    axes[0, 0].plot(epochs, history1['train_loss'], 'b-', label=f'{model1_name}')\n",
        "    axes[0, 0].plot(epochs, history2['train_loss'], 'r-', label=f'{model2_name}')\n",
        "    axes[0, 0].set_title('Training Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    # Validation Loss\n",
        "    axes[0, 1].plot(epochs, history1['val_loss'], 'b-', label=f'{model1_name}')\n",
        "    axes[0, 1].plot(epochs, history2['val_loss'], 'r-', label=f'{model2_name}')\n",
        "    axes[0, 1].set_title('Validation Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # Training Accuracy\n",
        "    axes[1, 0].plot(epochs, history1['train_acc'], 'b-', label=f'{model1_name}')\n",
        "    axes[1, 0].plot(epochs, history2['train_acc'], 'r-', label=f'{model2_name}')\n",
        "    axes[1, 0].set_title('Training Accuracy')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    # Validation Accuracy\n",
        "    axes[1, 1].plot(epochs, history1['val_acc'], 'b-', label=f'{model1_name}')\n",
        "    axes[1, 1].plot(epochs, history2['val_acc'], 'r-', label=f'{model2_name}')\n",
        "    axes[1, 1].set_title('Validation Accuracy')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Accuracy (%)')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrices(eval1, eval2, model1_name, model2_name, class_names):\n",
        "    \"\"\"Plot confusion matrices side by side\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    \n",
        "    # Model 1 Confusion Matrix\n",
        "    sns.heatmap(eval1['confusion_matrix'], annot=True, fmt='d', \n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                ax=axes[0], cmap='Blues')\n",
        "    axes[0].set_title(f'{model1_name} Confusion Matrix')\n",
        "    axes[0].set_xlabel('Predicted')\n",
        "    axes[0].set_ylabel('Actual')\n",
        "    \n",
        "    # Model 2 Confusion Matrix\n",
        "    sns.heatmap(eval2['confusion_matrix'], annot=True, fmt='d',\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                ax=axes[1], cmap='Reds')\n",
        "    axes[1].set_title(f'{model2_name} Confusion Matrix')\n",
        "    axes[1].set_xlabel('Predicted')\n",
        "    axes[1].set_ylabel('Actual')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_comparison_table(eval1, eval2, history1, history2, model1_name, model2_name):\n",
        "    \"\"\"Create a comprehensive comparison table\"\"\"\n",
        "    comparison_data = {\n",
        "        'Metric': [\n",
        "            'Final Validation Accuracy (%)',\n",
        "            'Test Accuracy (%)',\n",
        "            'Precision',\n",
        "            'Recall',\n",
        "            'F1-Score',\n",
        "            'Avg Training Time per Epoch (s)',\n",
        "            'Total Training Time (s)'\n",
        "        ],\n",
        "        model1_name: [\n",
        "            f\"{history1['val_acc'][-1]:.2f}\",\n",
        "            f\"{eval1['accuracy']*100:.2f}\",\n",
        "            f\"{eval1['precision']:.4f}\",\n",
        "            f\"{eval1['recall']:.4f}\",\n",
        "            f\"{eval1['f1_score']:.4f}\",\n",
        "            f\"{np.mean(history1['epoch_times']):.2f}\",\n",
        "            f\"{sum(history1['epoch_times']):.2f}\"\n",
        "        ],\n",
        "        model2_name: [\n",
        "            f\"{history2['val_acc'][-1]:.2f}\",\n",
        "            f\"{eval2['accuracy']*100:.2f}\",\n",
        "            f\"{eval2['precision']:.4f}\",\n",
        "            f\"{eval2['recall']:.4f}\",\n",
        "            f\"{eval2['f1_score']:.4f}\",\n",
        "            f\"{np.mean(history2['epoch_times']):.2f}\",\n",
        "            f\"{sum(history2['epoch_times']):.2f}\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    return df\n",
        "\n",
        "def visualize_sample_predictions(model1, model2, test_loader, class_names, \n",
        "                               model1_name, model2_name, num_samples=8):\n",
        "    \"\"\"Visualize sample predictions from both models\"\"\"\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "    \n",
        "    # Get a batch of test data\n",
        "    data_iter = iter(test_loader)\n",
        "    batch = next(data_iter)\n",
        "    images = batch['image'][:num_samples].to(device)\n",
        "    labels = batch['label'][:num_samples]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs1 = model1(images)\n",
        "        outputs2 = model2(images)\n",
        "        _, pred1 = torch.max(outputs1, 1)\n",
        "        _, pred2 = torch.max(outputs2, 1)\n",
        "    \n",
        "    # Plot results\n",
        "    fig, axes = plt.subplots(2, num_samples//2, figsize=(20, 8))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        # Denormalize image for display\n",
        "        img = images[i].cpu()\n",
        "        img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        img = img.permute(1, 2, 0).clamp(0, 1).numpy()\n",
        "        \n",
        "        # Model 1 predictions\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"{model1_name}: {class_names[pred1[i]]} (True: {class_names[labels[i]]})\")\n",
        "        axes[i].axis('off')\n",
        "        \n",
        "        # Model 2 predictions\n",
        "        axes[i + num_samples//2].imshow(img)\n",
        "        axes[i + num_samples//2].set_title(f\"{model2_name}: {class_names[pred2[i]]} (True: {class_names[labels[i]]})\")\n",
        "        axes[i + num_samples//2].axis('off')\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualization functions defined successfully!\")"
      ]
    }
  ]
}
